{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run active learning with pre-existing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from active_learn import get_mean_std\n",
    "from active.random import RandomSampling\n",
    "from active.mc_dropout import MCDropoutSampling\n",
    "from active.ensemble import EnsembleSampling\n",
    "from active.coreset import CoreSetSampling\n",
    "from active.policy_learner import PolicyLearner\n",
    "from train_helper import train_validate_model, reinit_seed\n",
    "from models.CNN import CNN\n",
    "import logging\n",
    "import numpy as np\n",
    "from models.model_helpers import weights_init\n",
    "import properties as prop\n",
    "from results.results_reader import read_results, set_results\n",
    "import copy\n",
    "import json\n",
    "from tqdm import trange\n",
    "from torch.utils.data import ConcatDataset\n",
    "import torch\n",
    "from data.data_helpers import make_tensordataset, stratified_split_dataset, concat_datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overwrite properties \n",
    "\n",
    "set dataset and policy weights to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dataset for evaluation\n",
    "# \"mnist\" \"fmnist\" \"kmnist\"\n",
    "prop.DATASET = \"mnist\" \n",
    "\n",
    "# set weights to load\n",
    "\n",
    "# fixed expert\n",
    "prop.POLICY_FILEPATH = \"./weights/fixed_experts/policy_99.pth\"\n",
    "\n",
    "# exponential expert\n",
    "#prop.POLICY_FILEPATH = \"./weights/exp_experts/policy_99.pth\"\n",
    "\n",
    "# exp. with additional random expert\n",
    "#prop.POLICY_FILEPATH = \"./weights/exp_random/policy_52.pth\"\n",
    "\n",
    "# these weights require edits in state calculation:\n",
    "\n",
    "# exp. with additional pool embedding \n",
    "#prop.POLICY_FILEPATH = \"./weights/exp_pool/policy_99.pth\"\n",
    "\n",
    "# exp with additional pool embedding + Coreset expert\n",
    "#prop.POLICY_FILEPATH = \"./weights/exp_pool_coreset/policy_99.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_learn(exp_num, StrategyClass, subsample):\n",
    "    # all strategies use same initial training data and model weights\n",
    "    reinit_seed(prop.RANDOM_SEED)\n",
    "    test_acc_list = []\n",
    "    model = CNN().apply(weights_init).to(device)\n",
    "    init_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    reinit_seed(exp_num*10)\n",
    "    dataset_pool, valid_dataset, test_dataset = get_data_splits()\n",
    "    train_dataset, pool_dataset = stratified_split_dataset(dataset_pool, 20, 10)\n",
    "\n",
    "    # initial data\n",
    "    strategy = StrategyClass(dataset_pool, valid_dataset, test_dataset, device)\n",
    "\n",
    "    t = trange(1, prop.NUM_ACQS + 1, desc=\"Aquisitions (size {})\".format(prop.ACQ_SIZE), leave=True)\n",
    "    for acq_num in t:  # range(1, prop.NUM_ACQS + 1):\n",
    "        model.load_state_dict(init_weights)  # model.apply(weights_init)\n",
    "\n",
    "        test_acc = train_validate_model(model, device, train_dataset, valid_dataset, test_dataset)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "        if subsample:\n",
    "            subset_ind = np.random.choice(a=len(pool_dataset), size=prop.K, replace=False)\n",
    "            pool_subset = make_tensordataset(pool_dataset, subset_ind)\n",
    "            sel_ind, remain_ind = strategy.query(prop.ACQ_SIZE, model, train_dataset, pool_subset)\n",
    "            q_idxs = subset_ind[sel_ind]  # from subset to full pool\n",
    "            remaining_ind = list(set(np.arange(len(pool_dataset))) - set(q_idxs))\n",
    "            sel_dataset = make_tensordataset(pool_dataset, q_idxs)\n",
    "            train_dataset = concat_datasets(train_dataset, sel_dataset)\n",
    "            pool_dataset = make_tensordataset(pool_dataset, remaining_ind)\n",
    "        else:\n",
    "            # all strategies work on k-sized windows in semi-batch setting\n",
    "            sel_ind, remaining_ind = strategy.query(prop.ACQ_SIZE, model, train_dataset, pool_dataset)\n",
    "            sel_dataset = make_tensordataset(pool_dataset, sel_ind)\n",
    "            pool_dataset = make_tensordataset(pool_dataset, remaining_ind)\n",
    "            train_dataset = concat_datasets(train_dataset, sel_dataset)\n",
    "\n",
    "        logging.info(\"Accuracy for {} sampling and {} acquisition is {}\".format(strategy.name, acq_num, test_acc))\n",
    "    return test_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prop.RESULTS_FILE = \"./results/experiments_{}_TMP.json\".format(prop.DATASET)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if prop.DATASET.lower() == \"mnist\":\n",
    "    from data.mnist import get_data_splits\n",
    "    print(\"Training on MNIST\")\n",
    "elif prop.DATASET.lower() == \"fmnist\":\n",
    "    from data.fmnist import get_data_splits\n",
    "    print(\"Training on Fashion-MNIST\")\n",
    "elif prop.DATASET.lower() == \"kmnist\":\n",
    "    from data.kmnist import get_data_splits\n",
    "    print(\"Training on KMNIST\")\n",
    "\n",
    "torch.cuda.cudnn_enabled = False\n",
    "reinit_seed(prop.RANDOM_SEED)\n",
    "logging.info(\"later dumping to {}\".format(prop.RESULTS_FILE))\n",
    "strategies = [PolicyLearner] \n",
    "results = read_results()\n",
    "for strategy in strategies:\n",
    "    test_acc = [active_learn(exp_num, strategy, subsample=True) for exp_num in range(prop.NUM_EXPS)]\n",
    "    mean, std = get_mean_std(test_acc)\n",
    "    results[strategy.name] = [mean.tolist(), std.tolist()]\n",
    "\n",
    "\"\"\"strategies = [RandomSampling, EnsembleSampling, MCDropoutSampling, CoreSetSampling] \n",
    "for strategy in strategies:\n",
    "    test_acc = [active_learn(exp_num, strategy, subsample=False) for exp_num in range(prop.NUM_EXPS)]\n",
    "    mean, std = get_mean_std(test_acc)\n",
    "    results[strategy.name] = [mean.tolist(), std.tolist()]\"\"\"\n",
    "\n",
    "logging.info(\"dumping results to {}\".format(prop.RESULTS_FILE))\n",
    "set_results(results, results_file=prop.RESULTS_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from results.results_reader import read_results\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "INIT_SIZE = 20\n",
    "ACQ_SIZE = 10\n",
    "\n",
    "current_palette = sns.color_palette()\n",
    "sns.set_style('whitegrid')\n",
    "figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "linewidth = 3\n",
    "markersize = 5\n",
    "with_stddev = True\n",
    "\n",
    "def plot(keys, results, strategies, acq_size=ACQ_SIZE, ylim=(0,1), lim=1000, loc='lower right'):\n",
    "    \n",
    "    for i in keys:\n",
    "        means = np.array(results[strategies[i]][0])\n",
    "        std = np.array(results[strategies[i]][1])\n",
    "        x = [x * acq_size + 20 for x in range(len(means))]\n",
    "        if labels[i].endswith('Random'):\n",
    "            color = 'black'\n",
    "            plt.plot(x, means, marker='.', label=labels[i], linestyle='--', linewidth=5, markersize=markersize,\n",
    "                     color=color)\n",
    "            if with_stddev:\n",
    "                plt.fill_between(x, means + std, means - std, alpha=0.1, color=color)\n",
    "        else:\n",
    "            plt.plot(x, means, marker='.', label=labels[i], linewidth=linewidth, markersize=markersize)\n",
    "            if with_stddev:\n",
    "                plt.fill_between(x, means + std, means - std, alpha=0.1)\n",
    "    plt.legend(loc=loc, prop={'size': 10})\n",
    "    plt.ylabel(\"Test data accuracy score\")\n",
    "    plt.xlabel(\"Labeling effort\")\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlim(0, lim)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prop.DATASET == \"mnist\":\n",
    "    strategies = ['random', 'mc-dropout', 'ensemble', 'coreset_all', 'policy-learner_state_True']\n",
    "    labels = ['Random', 'MC Dropout', 'Ensemble', 'Corest', 'Our method']\n",
    "    keys = [0, 1, 2, 3, 4]\n",
    "    results = read_results(results_file=\"./results/experiments_mnist_1000_10_baselines.json\")\n",
    "    results.update(read_results(results_file=\"./results/experiments_mnist_1000_10_coresets.json\"))\n",
    "    results.update(read_results(results_file=\"./results/experiments_mnist_TMP.json\"))\n",
    "    plot(keys, results, strategies, acq_size=10, ylim=(0.6,1), loc='lower right')\n",
    "elif prop.DATASET == \"fmnist\":\n",
    "    strategies = ['random', 'mc-dropout', 'ensemble', 'coreset_all', 'policy-learner_state_True']\n",
    "    labels = ['Random', 'MC Dropout', 'Ensemble', 'Corest', 'Our method']\n",
    "    keys = [0, 1, 2, 3, 4]\n",
    "    results = read_results(results_file=\"./results/experiments_fmnist_1000_10_baselines.json\")\n",
    "    results.update(read_results(results_file=\"./results/experiments_fmnist_1000_10_coresets.json\"))\n",
    "    results.update(read_results(results_file=\"./results/experiments_fmnist_TMP.json\"))\n",
    "    plot(keys, results, strategies, acq_size=10, ylim=(0.6,1), loc='lower right')\n",
    "elif prop.DATASET == \"kmnist\":\n",
    "    strategies = ['random', 'mc-dropout', 'ensemble', 'coreset_all', 'policy-learner_state_True']\n",
    "    labels = ['Random', 'MC Dropout', 'Ensemble', 'Corest', 'Our method']\n",
    "    keys = [0, 1, 2, 3, 4]\n",
    "    results = read_results(results_file=\"./results/experiments_kmnist_1000_10_baselines.json\")\n",
    "    results.update(read_results(results_file=\"./results/experiments_kmnist_1000_10_coresets.json\"))\n",
    "    results.update(read_results(results_file=\"./results/experiments_kmnist_TMP.json\"))\n",
    "    plot(keys, results, strategies, acq_size=10, ylim=(0.5,.85), loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
